# HÆ°á»›ng Dáº«n TÃ­ch Há»£p VTO (Virtual Try-On) vá»›i CatVTON

## ğŸ“‹ Tá»•ng Quan

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p sáºµn cáº¥u trÃºc cÆ¡ báº£n cho VTO. Hiá»‡n táº¡i Ä‘ang sá»­ dá»¥ng **mock pipeline** (placeholder). Báº¡n cáº§n thay tháº¿ báº±ng **CatVTON pipeline tháº­t** tá»« code Kaggle.

---

## ğŸ—ï¸ Cáº¥u TrÃºc ÄÃ£ Táº¡o

### 1. Backend (`retrieval_service/`)

**`vto_service.py`**:
- Module chá»©a VTO pipeline functions
- Hiá»‡n táº¡i: Mock implementation
- Cáº§n thay tháº¿: CatVTON pipeline tháº­t

**`main.py`**:
- Endpoint: `POST /vto`
- Nháº­n: `person_image` (base64), `cloth_image` (URL hoáº·c base64)
- Tráº£ vá»: `result_image` (base64)

### 2. Frontend (`components/`)

**`vto-modal.tsx`**:
- Upload pose image
- Gá»i API `/vto`
- Hiá»ƒn thá»‹ káº¿t quáº£ (3 áº£nh: pose gá»‘c, sáº£n pháº©m, káº¿t quáº£)

**`product-card.tsx`**:
- Button "Try On" (Zap icon) Ä‘Ã£ cÃ³ sáºµn
- Má»Ÿ VTOModal khi click

---

## ğŸ”§ CÃ¡ch TÃ­ch Há»£p CatVTON Tháº­t

### BÆ°á»›c 1: CÃ i Äáº·t Dependencies

ThÃªm vÃ o `retrieval_service/requirements.txt`:

```txt
# VTO Dependencies
diffusers==0.24.0
transformers==4.36.2
huggingface-hub==0.24.6
opencv-python-headless>=4.8.0
pillow>=10.0.0
accelerate>=0.30.0
peft==0.7.1
tokenizers==0.15.0
```

### BÆ°á»›c 2: Clone CatVTON Repository

```bash
cd retrieval_service
git clone https://github.com/Zheng-Chong/CatVTON.git
```

### BÆ°á»›c 3: Cáº­p Nháº­t `vto_service.py`

Thay tháº¿ pháº§n `_load_models()` vÃ  `run_virtual_tryon()` báº±ng code tá»« Kaggle:

```python
# Thay tháº¿ pháº§n nÃ y trong vto_service.py:

def _load_models():
    """Load CatVTON models."""
    global _vto_pipeline, _seg_processor, _seg_model
    global _clip_model, _clip_processor, _blip_model, _blip_processor
    
    if _vto_pipeline is not None:
        return
    
    device = _get_device()
    
    # 1. Load Segformer (from your Kaggle code)
    from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation
    _seg_processor = SegformerImageProcessor.from_pretrained("mattmdjaga/segformer_b2_clothes")
    _seg_model = AutoModelForSemanticSegmentation.from_pretrained("mattmdjaga/segformer_b2_clothes").to(device)
    
    # 2. Load CatVTON Pipeline (from your Kaggle code)
    import sys
    sys.path.append("CatVTON")  # Add CatVTON to path
    from model.pipeline import CatVTONPipeline
    
    _vto_pipeline = CatVTONPipeline(
        base_ckpt="runwayml/stable-diffusion-inpainting",
        attn_ckpt="ckpt",  # Download from HuggingFace
        attn_ckpt_version="vitonhd",
        weight_dtype=torch.float16,
        device=device,
        skip_safety_check=True,
    )
    
    # 3. Load CLIP (from your Kaggle code)
    from transformers import CLIPProcessor, CLIPModel
    _clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
    _clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    
    # 4. Load BLIP (from your Kaggle code)
    from transformers import BlipProcessor, BlipForConditionalGeneration
    _blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    _blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to(device)
```

### BÆ°á»›c 4: Cáº­p Nháº­t Functions

Thay tháº¿ cÃ¡c functions trong `vto_service.py`:

```python
def classify_cloth_type(image: Image.Image) -> Tuple[str, float]:
    """Use CLIP model from Kaggle code."""
    if _clip_model is None or _clip_processor is None:
        return "upper", 0.9
    
    labels = ["upper garment, shirt, top, jacket", "lower body clothing, pants, skirt, jeans"]
    inputs = _clip_processor(text=labels, images=image, return_tensors="pt", padding=True).to(_get_device())
    
    with torch.no_grad():
        probs = _clip_model(**inputs).logits_per_image.softmax(dim=1)
    
    idx = probs.argmax().item()
    confidence = probs[0][idx].item()
    return ("upper" if idx == 0 else "lower"), confidence

def generate_caption(image: Image.Image) -> str:
    """Use BLIP model from Kaggle code."""
    if _blip_model is None or _blip_processor is None:
        return "clothing item"
    
    inputs = _blip_processor(image, return_tensors="pt").to(_get_device())
    with torch.no_grad():
        out = _blip_model.generate(**inputs, max_new_tokens=30)
    caption = _blip_processor.decode(out[0], skip_special_tokens=True)
    return caption

def get_mask_from_segformer(image: Image.Image, cloth_type: str = "upper") -> Image.Image:
    """Use Segformer model from Kaggle code."""
    # Copy code tá»« CELL 3 cá»§a Kaggle
    # ...
```

### BÆ°á»›c 5: Cáº­p Nháº­t `run_virtual_tryon()`

Thay tháº¿ báº±ng code tá»« Kaggle CELL 3:

```python
def run_virtual_tryon(...):
    # Copy toÃ n bá»™ logic tá»« CELL 3 cá»§a Kaggle
    # Sá»­ dá»¥ng _vto_pipeline, _seg_model, _clip_model, _blip_model
    # ...
```

---

## ğŸ”‘ HuggingFace Token

Cáº§n set HuggingFace token Ä‘á»ƒ download models:

```python
# Trong vto_service.py hoáº·c main.py
from huggingface_hub import login
HF_TOKEN = os.environ.get("HF_TOKEN", "your_token_here")
login(HF_TOKEN)
```

Hoáº·c set environment variable:
```bash
export HF_TOKEN="your_token_here"
```

---

## ğŸ“ LÆ°u Ã Quan Trá»ng

### 1. Model Loading
- Models ráº¥t lá»›n (vÃ i GB)
- Cáº§n GPU Ä‘á»ƒ cháº¡y nhanh (CPU sáº½ ráº¥t cháº­m)
- CÃ³ thá»ƒ lazy load (chá»‰ load khi cáº§n)

### 2. Performance
- VTO pipeline máº¥t ~5-30 giÃ¢y tÃ¹y GPU
- Cáº§n timeout phÃ¹ há»£p á»Ÿ frontend
- CÃ³ thá»ƒ cache results

### 3. Error Handling
- Handle memory errors (models lá»›n)
- Handle timeout
- Fallback náº¿u models khÃ´ng load Ä‘Æ°á»£c

### 4. Production
- CÃ¢n nháº¯c cháº¡y VTO trÃªn server riÃªng (GPU server)
- Hoáº·c dÃ¹ng cloud service (AWS, GCP)
- CÃ³ thá»ƒ queue system cho VTO requests

---

## ğŸ§ª Test Flow

1. User: "Show me polo"
2. System: Hiá»ƒn thá»‹ products
3. User: Click "Try On" button trÃªn product
4. VTOModal má»Ÿ â†’ Upload pose image
5. Click "Thá»­ Ä‘á»“ ngay"
6. Frontend gá»i `/vto` API
7. Backend cháº¡y CatVTON pipeline
8. Tráº£ vá» result image
9. Frontend hiá»ƒn thá»‹ káº¿t quáº£

---

## ğŸš€ Next Steps

1. **Thay tháº¿ mock pipeline** báº±ng CatVTON tháº­t
2. **Test vá»›i real images** tá»« user
3. **Optimize performance** (caching, batching)
4. **Add error handling** tá»‘t hÆ¡n
5. **Consider GPU server** náº¿u cáº§n scale

---

## ğŸ“š Files Cáº§n Sá»­a

- `retrieval_service/vto_service.py` - Thay mock báº±ng CatVTON tháº­t
- `retrieval_service/requirements.txt` - ÄÃ£ thÃªm dependencies
- `retrieval_service/main.py` - Endpoint `/vto` Ä‘Ã£ cÃ³
- `components/vto-modal.tsx` - UI Ä‘Ã£ hoÃ n chá»‰nh
- `components/product-card.tsx` - Button Ä‘Ã£ cÃ³ sáºµn

---

## âš ï¸ Current Status

âœ… **ÄÃ£ hoÃ n thÃ nh:**
- Backend endpoint `/vto`
- Frontend VTOModal vá»›i upload
- UI/UX hoÃ n chá»‰nh
- Error handling cÆ¡ báº£n

âš ï¸ **Cáº§n lÃ m:**
- Thay mock pipeline báº±ng CatVTON tháº­t
- Test vá»›i real models
- Optimize performance

Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u thay tháº¿ mock pipeline báº±ng code CatVTON tá»« Kaggle!

